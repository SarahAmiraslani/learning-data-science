{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Essential Python Libraries\n",
    "- **NumPy**, short for numerical Python. It provides the data structures and algorithms needd for most scientific applications involving numerical data in Python. \n",
    "    - NumPy contains: \n",
    "        - A fast and efficient multidimensional array object *ndarray*\n",
    "        - Functions for performing element-wise computations with arrays or mathematical operations between arrays. \n",
    "        - Tools for reading and writing array-based datasets to disk\n",
    "        - Linear algebra operations\n",
    "    - Beyond the fast array-processing capabilities that NumPy adds to Python, one of its primary uses in data analysis is as a contained for data to be passed between algorithms and libraries. \n",
    "       - For numerical data, NumPy arrays are efficient for storing and manipulating data than the other built in Python data structures. Thus many numerical computing tools for Python either assume NumPy arrays as a primary data structure or they target seamless interoperability with NumPy. \n",
    "       \n",
    "- **pandas** provides high-level data structures and functions designed to make working with structured or tabular data fast, easy, and expressive. The primary objects in pandas are the `DataFrame`, a tabular column-oriented data structure with both row and column labels, and the `Series`, a one dimensional labeled array object. \n",
    "    - pandas blends the high-performance, array-computing ideas of NumPy with the flexible data manipulation capabilities of spreadsheets and relational databases.\n",
    "        - It provides sophisticated insexing functionality to make it easy to reshape, slice and dice, perform aggregations, and select subsets of data.\n",
    "    - Note, as a result of having been built initially to solve finance and business analytics problems, pandas features especially deep time series functionality and tools well suited for working with time-indexed data generated by business processes. \n",
    "    \n",
    "- **matplotlib** is the most popular Python library for producing plots and other two-dimensional data visualizations. \n",
    "\n",
    "- **SciPy** is a collection of packages addressing a number of different standard problem domains in scientific computing. \n",
    "    - Here are some of the packages included:\n",
    "        - `scipy.integrate` included numerical integaration routines and differential equation solvers. \n",
    "        - `scipy.linalg` includes linear algebra routines and matrix decompositions extending beyond those provided in `numpy.linalg`.\n",
    "        - `scipy.optimize` includes function optimizers (minimizeers) and root finding algorithms. \n",
    "        - `scipy.signal` includes signal processing tools.\n",
    "        - `scipy.sparse` includes sparse matrices and sparse linear system solvers. \n",
    "        - `scipy.stats` includes standard continous and discrete probability distributions (density functions, samplers, continous distribution functions), various statistical tests, and more descriptive statistics. \n",
    "- **scikit-learn** is the premier general-purpose machine learning toolkit in Python. \n",
    "    - It includes submodules for models such as: \n",
    "        - Classification: SVM, nearest neighbors, random forest, logistic regression, etc.\n",
    "        - Regression: Lasso, ridge regression, etc.\n",
    "        - Clustering: k-means, spectral clustering, etc.\n",
    "        - Dimensionality reduction: PCA, feature selection, matrix factorization, etc.\n",
    "        - Model selection: Grid search, cross-validation, metrics\n",
    "        - Preprocessing: Feature extraction, normalization\n",
    "- **statsmodels** is a statistical analysis package that contains algorithms for classical statistics and econometrics. \n",
    "    - It includes submodules such as: \n",
    "        - Regression models: Linear regression, generalized linear models, robust linear models, linear mixed effects models, etc.\n",
    "        - Analysis of variance (ANOVA)\n",
    "        - Time series analysis: AR, ARMA, ARIMA, VAR, and other models\n",
    "        - Nonparametric methods: Kernel density estimation, kernel regression\n",
    "        - Visualization of statistical model results\n",
    "    - statsmodels is more focused on statistical inference, providing uncertainty estimates and p-values for parameters. scikit-learn, by contrast is more prediction-focused. \n",
    "    \n",
    "Data science tasks generally fall into a number of different broad groups:\n",
    "- *Interacting with the outside world*\n",
    "    - Reading and writing with a variety of file formats and data stores\n",
    "- *Preparation*\n",
    "    - Cleaning, munging, combining, normalizing, reshaping, slicing and dicing, and transforming data for analysis. \n",
    "- *Transformation*\n",
    "    - Applying mathematical and statistical operations to groups of datasets to derive new datasets. \n",
    "- *Modeling and computation*\n",
    "    - Connecting your data to statistical models, machine learning algorithms, or other computational tools. \n",
    "- *Presentation*\n",
    "    - Creating interactive or static graphical visualizations or textual summaries. \n",
    "    \n",
    "**Import Conventions**\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels as sm\n",
    "```\n",
    "Note: it's considered bad practice in Python software development to import everything from a large package. When you can you should only import what you need. \n",
    "\n",
    "**Jargon**\n",
    "- *Munge/munging/wrangling*\n",
    "    - Describes the process of manipulating unstructured and/or messy data into a structured or clearn form. \n",
    "- *Pseudocode*\n",
    "    - A description of an algorithm or process that takes a code-like form while n ot being actual valid code. \n",
    "- *Syntactic sugar*\n",
    "    - Programming syntax that does not add new features, but makes something more convenient or easier to type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Opening text files**\n",
    "To open a file for reading or writing, use the built-in `open` function with either a relative or absolute path. When you `open` to create file objects, it is important to explicitly clsoe the file when you are finished with it. Closing the file releases its resources back to the operating system.\n",
    "\n",
    "One way to make it easuer to clean up open files is to use the `with` statement. This will automatically close the file `f` when exiting the `with` block.\n",
    "\n",
    "Careful: if we had typed `f = open(path,'w')`, a *new file* would have been created, overwriting the current version of the file. \n",
    "\n",
    "Python file modes\n",
    "\n",
    "|**Mode**| **Description**|\n",
    "|--------|----------------|\n",
    "|`r` |Read-only mode|\n",
    "|`w` |Write-only mode; creates a new file (erasing the data for any file with the same name)|\n",
    "|`x` |Write-only mode; creates a new file, but fails if the file path already exists|\n",
    "|`a` |Append to existing file (create the file if it does not already exist)|\n",
    "|`r+` |Read and write|\n",
    "|`b` |Add to mode for binary files (i.e., `'rb'` or `'wb'`)|\n",
    "|`t` |Text mode for files (automatically decoding bytes to Unicode). This is the default if not specified. Add t to other modes to use this (i.e., `'rt'` or `'xt'`)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sarahamiraslani/Learning/Python/Data Science'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/sarahamiraslani/Learning/data/segismundo.txt'\n",
    "with open(path) as f:\n",
    "    lines = [x.rstrip() for x in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sueña el rico en su riqueza,',\n",
       " 'que más cuidados le ofrece;',\n",
       " '',\n",
       " 'sueña el pobre que padece',\n",
       " 'su miseria y su pobreza;',\n",
       " '',\n",
       " 'sueña el que a medrar empieza,',\n",
       " 'sueña el que afana y pretende,',\n",
       " 'sueña el que agravia y ofende,',\n",
       " '',\n",
       " 'y en el mundo, en conclusión,',\n",
       " 'todos sueñan lo que son,',\n",
       " 'aunque ninguno lo entiende.',\n",
       " '']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sueña el rico en su riqueza,\\n',\n",
       " 'que más cuidados le ofrece;\\n',\n",
       " '\\n',\n",
       " 'sueña el pobre que padece\\n',\n",
       " 'su miseria y su pobreza;\\n',\n",
       " '\\n',\n",
       " 'sueña el que a medrar empieza,\\n',\n",
       " 'sueña el que afana y pretende,\\n',\n",
       " 'sueña el que agravia y ofende,\\n',\n",
       " '\\n',\n",
       " 'y en el mundo, en conclusión,\\n',\n",
       " 'todos sueñan lo que son,\\n',\n",
       " 'aunque ninguno lo entiende.\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For readable files, some of the most commonly used methods are `read`, `seek`, and `tell`. \n",
    "- `read` returns a certain number of characters from the file. \n",
    "- `tell` gives you the current position.\n",
    "- `seek` changes the file position. \n",
    "\n",
    "Important Python file methods or attributes\n",
    "\n",
    "|**Method**|**Description**|\n",
    "|----------|---------------|\n",
    "|`read()` |Return data from file as a string, with optional size argument indicating the number of bytes to read|\n",
    "|`readlines()`| Return list of lines in the file, with optional size argument|\n",
    "|`write()` | Write passed string to file|\n",
    "|`writelines()`| Write passed sequence of strings to the file|\n",
    "|`close()` | Close the handle |\n",
    "|`flush()` | Flush the internal I/O buffer to disk|\n",
    "|`seek()` | Move to indicated file position (integer)|\n",
    "|`tell()` | Return current file position as integer|\n",
    "|`closed` |True if the file is closed|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data analysis applications, the main areas of functionality include:\n",
    "- Fast vectorized array operations for data cleaning, subsetting, filtering, transforming, and any other kinds of computations. \n",
    "- Common array algorithms like sorting, unique, and set operations. \n",
    "- Efficient descriptive statistics and aggregating/summarizing data\n",
    "- Data alignment and relational data manipulations for merging and joining together heterogeneous datasets.\n",
    "- Expressing conditional logic as array expressions instead of loops with `if-elif-else` branches. \n",
    "- Group-wise data manipulations (aggregation, transformation, function application)\n",
    "\n",
    "One of the reasons NumPy is so important for numerical computations in Python is because it is designed for efficiency on large arrays of data. There are a number of reasons for this. \n",
    "- NumPy interally stores data in a contiguous block of memory, independent of other built-in Python objects. NumPy arrays also use much less memory than built-in Python sequences. \n",
    "- NumPy operations perform complex computations on entire arrays without the need for Python `for` loops. \n",
    "\n",
    "**The NumPy ndarray: A Multidimensional Array Object**\n",
    "Arrays enable you to perform mathematical operations on whole blocks of data using similar syntax to the equivalent operations between scalar elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.66574468 -0.9375177   0.87080909]\n",
      " [-0.42403869  0.25635012 -0.67678059]]\n",
      "\n",
      "\n",
      "[[-6.6574468  -9.37517698  8.70809091]\n",
      " [-4.24038693  2.56350125 -6.76780587]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.random.randn(2,3)\n",
    "print(data)\n",
    "\n",
    "print('\\n')\n",
    "print(data * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ndarray is a generic multidimensional container for homogeneous data; that is, all of the elements must be the same type. \n",
    "\n",
    "**Creating ndarrays**\n",
    "The easiest way to create an array is to use the `array` function. This accepts any sequence-like object and produce a new NumPy array containing the passed data. Nested sequences, like a list of equal-length lists, will be converted into a multidimensional array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6. , 7.5, 8. , 0. , 1. ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = [6, 7.5, 8, 0, 1]\n",
    "arr1 = np.array(data1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
    "arr2 = np.array(data2)\n",
    "arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless explicityly specified, `np.array` tries to infer a good data type for the array it creates. The data type is stored in a special `dtype` metadata object.\n",
    "\n",
    "Array creation functions\n",
    "\n",
    "|**Function** | **Description**|\n",
    "|-------------|----------------|\n",
    "|`array` |Convert input data (list, tuple, array, or other sequence type) to an ndarray either by inferring a dtype or explicitly specifying a dtype; copies the input data by default|\n",
    "|`asarray` |Convert input to ndarray, but do not copy if the input is already an ndarray arange Like the built-in range but returns an ndarray instead of a list| \n",
    "|`ones`,`ones_like` | Produce an array of all 1s with the given shape and dtype; ones_like takes another array and produces a ones array of the same shape and dtype|\n",
    "|`zeros`, `zeros_like` | Like ones and ones_like but producing arrays of 0s instead|\n",
    "|`empty`,`empty_like` | Create new arrays by allocating new memory, but do not populate with any values like ones and zeros|\n",
    "|`full`, `full_like` |Produce an array of the given shape and dtype with all values set to the indicated “fill value” `full_like` takes another array and produces a filled array of the same shape and dtype|\n",
    "|`eye`, `identity`| Create a square N × N identity matrix (1s on the diagonal and 0s elsewhere)|\n",
    "\n",
    "**Data Types for ndarrays**\n",
    "dtypes are a source of NumPy's flexibility for interacting with data coming from other systems. \n",
    "\n",
    "It's often only necessary to care about the general *kind* of data you're dealing with, whether floating point, complex, integer, boolean, string, or general Python object. However, when you need more control over how data are stored in memory and on disk, especially with large datsets, it is good to know that you can have control over the storage type. \n",
    "\n",
    "NumPy data types\n",
    "\n",
    "|**Types** | **Type code** | **Description**|\n",
    "|----------|---------------|----------------|\n",
    "|`int8`, `uint8`| `i1`, `u1`| Signed and unsigned 8-bit (1 byte) integer types|\n",
    "|`int16`, `uint16`| `i2`, `u2`| Signed and unsigned 16-bit integer types|\n",
    "|`int32`, `uint32`| `i4`, `u4`| Signed and unsigned 32-bit integer types|\n",
    "|`int64`, `uint64`| `i8`, `u8`| Signed and unsigned 64-bit integer types|\n",
    "|`float16`| `f2`| Half-precision floating point|\n",
    "|`float32`| `f4` or `f`| Standard single-precision floating point; compatible with C float|\n",
    "|`float64`| `f8` or `d`|Standard double-precision floating point; compatible with C double and Python float object|\n",
    "|`loat128`| `f16` or `g`| Extended-precision floating point|\n",
    "|`complex64`,`complex128`, `complex256`|`c8`, `c16`, `c32`|Complex numbers represented by two 32, 64, or 128 floats, respectively|\n",
    "|`bool`| `?` |Boolean type storing True and False values\n",
    "|`object`| `O` |Python object type; a value can be any Python object\n",
    "|`string_`| `S` |Fixed-length ASCII string type (1 byte per character); for example, to create a string dtype with length 10, use 'S10'|\n",
    "|`unicode_` |`U` |Fixed-length Unicode type (number of bytes platform specific); same specification semantics as string_ (e.g., 'U10')|\n",
    "\n",
    "You can explicitly convert or *cast* an array from one dtype to another usin ndarray's `astype` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "int64\n",
      "\n",
      "\n",
      "[1. 2. 3. 4. 5.]\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "print(arr)\n",
    "print(arr.dtype)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "float_arr = arr.astype(np.float64)\n",
    "print(float_arr)\n",
    "print(float_arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you case some floating-point numbers to be of integer dtype, the decimal part will be truncated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.7 -1.2 -2.6  0.5 12.9 10.1]\n",
      "float64\n",
      "\n",
      "\n",
      "[ 3 -1 -2  0 12 10]\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([3.7, -1.2, -2.6, 0.5, 12.9, 10.1])\n",
    "print(arr)\n",
    "print(arr.dtype)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "int_arr = arr.astype(np.int64)\n",
    "print(int_arr)\n",
    "print(int_arr.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Indexing and Slicing**\n",
    "An important distinction from Python's built-in lists is that array slices are *views* of the original array. This means that the data is not copied, and any modifications to the view will be reflected in the source array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "[ 0  1  2  3  4 12 12 12  8  9]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "print(arr)\n",
    "\n",
    "arr[5:8] = 12\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2     3     4    12 12345    12     8     9]\n"
     ]
    }
   ],
   "source": [
    "# create a slice of arr\n",
    "arr_slice = arr[5:8]\n",
    "\n",
    "# notice: when we change values in arr_slice, the mutations are reflected in the original\n",
    "# array arr\n",
    "arr_slice[1] = 12345\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a copy of a slice of an ndarray instead of a view, you will need to explicitly copy the array -- for example, `arr[5:8].copy()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3d = np.array(([1,2,3,4],[4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
